Iterable -> Collections
Collections -> List -> ArrayList
					-> LinkedList
					-> Vector
			-> AbstractCollections - > AbstractList -> Vector - >Stack	
			-> Set -> HashSet
				   -> LinkedHashSet	
				   -> TreeSet (Implements SortedSet)
				   -> EnumSet 
				   -> BitSet
			-> Queue	   
Map is a separate interface it doesn't come under collections package
Map -> HashMap
	-> LinkedHashMap
	-> TreeMap
	-> EnumMap
	-> IdentityHashMap
	-> WeakHashMap
	
-----------------
List:
List is the ordered interface—allows duplicates.
Use wrappers or factory methods for immutability or fixed size.

1.ArrayList
Backed by a dynamic array; supports fast random access—O(1) for .get(index).
Auto-resizes when capacity exceeds; elements shift on insertion/removal in the middle 

2.LinkedList
Implemented as a doubly-linked list; optimal for frequent insertions/deletions, especially at ends—O(1).
Slower for random access—O(n) to reach an index .
Also implements Queue and Deque.

3.Vector (legacy)
Similar to ArrayList, but thread-safe (methods are synchronized).
Outdated due to synchronization overhead 

4.Stack (legacy)
Extends Vector; implements LIFO stack with methods like push(), pop(), peek()

5.CopyOnWriteArrayList (concurrent)
Thread-safe; uses copy-on-write strategy—ideal for scenarios with many reads but 
few writes (not in our search but a known JDK class).

Frequent random reads -> ArrayList
Frequent middle insert/remove -> LinkedList
Thread-safe list with few writes -> CopyOnWriteArrayList
Synchronization needed -> Vector or concurrent alternatives
LIFO stack operations -> Deque (ArrayDeque) over legacy Stack
Note: Deque (like ArrayDeque) is preferred over Stack for LIFO structures.

-----------------------------------------------------------------------
ArrayList Internal Implementation:
1.Internally, ArrayList uses a transient Object[] elementData to store its elements
2.new ArrayList() uses a shared empty array DEFAULTCAPACITY_EMPTY_ELEMENTDATA, and only allocates the 
default capacity (10) when the first element is added
3.new ArrayList(int initialCapacity) directly allocates an Object[] of that size, 
or uses an empty array if you pass zero
4.new ArrayList(Collection<? extends E> c) allocates based on c.size(), 
copying its elements via Arrays.copyOf(...)
5.Before each add(e), ArrayList checks if capacity is sufficient via ensureCapacityInternal(minCapacity)
When full, grow(minCapacity) expands the array using:
int oldCapacity = elemA modCount++ is used to track structural changes (helps with fail-fast iterators) 
intData.length;
int newCapacity = oldCapacity + (oldCapacity >> 1);
if (newCapacity < minCapacity) newCapacity = minCapacity;
elementData = Arrays.copyOf(elementData, newCapacity);
This scales capacity by ~50% (1.5×) 
This amortized doubling ensures that while individual resizes are O(n), the average cost per add remains O(1)
After capacity is assured, the element is placed at elementData[size++].
A modCount++ is used to track structural changes (helps with fail-fast iterators) 
6.Removing Elements
Removing Elements
int newSize = size - 1;
if (newSize > index)
  System.arraycopy(es, index + 1, es, index, newSize - index);
es[size = newSize] = null;
modCount++;
That shifts subsequent elements left and nullifies the old last slot; it does not shrink the array 
7.ArrayList does not auto-shrink, so old capacity remains until you explicitly call trimToSize()
8.Using Arrays.copyOf(...) is efficient as it uses System.arraycopy, which benefits from data locality and CPU caching
get(index) / set(index)	O(1) random access
add(e) (amortized adding at the end)	O(1) – behind the scenes
add(e) (adding in the middle)	O(n)
remove(index) / shift	O(n) due to copy
contains(e) / indexOf(e)	O(n) linear search
---------------------------------------------------------------------------------

LinkedList Internal Implementation:
1.Uses Doubly-linked structure with Node<E> holding: E item, Node<E> next, Node<E> prev
2.LinkedList stores:Node<E> first, Node<E> last — fast access to both ends. Here first is head and last is tail
int size — current count of elements, modCount — tracks structural changes for fail-fast iterators 
3.add(E e) / addLast(E e):Time Complexity: O(1)
Link new node to current last.
update last (and first if list was empty).
Increment size & modCount.
4.addFirst(E e):Time Complexity: O(1)
Insert at head in the same constant-time manner.
5.add(int index, E e):Time Complexity: O(n) traversal + O(1) insertion → O(n)
Traverse from first or last (whichever is closer) to reach index.
Adjust pointers to splice in new node.
6.get(int index) / set(int index, E e): Time Complexity: O(n) 
Traverse to index using bidirectional search.
Get or update data.
7.removeFirst() / removeLast(): Time Complexity: O(1)
Detach node at head/tail.
Fix first or last and null pointers for GC.
8.remove(int index):Time Complexity: O(n) (due to traversal)
Navigate to node & unlink(node) – adjust pointers, decrement size.
9.remove(Object o):Time Complexity: O(n) 
Linear search for first matching node.
Unlink upon match.
10.Iterator.remove():Time Complexity: O(1)
Works directly on current node.

So to sum up..
addFirst, addLast, add(E) -> O(1)
removeFirst, removeLast ->	O(1)
Iterator.remove() -> O(1)
add(index, E), get(index), set(index, E) -> O(n)
remove(index), remove(Object) -> O(n)
contains(o), indexOf(o) -> O(n)
When to use LinkedList: ?
Ideal for frequent inserts or removals at both ends or when you use iterator-based modifications
Not suited for performance-critical random access — prefer ArrayList in these cases 

------------------------------------------------------------------------------------------------
Vector Internal Implementation:
1.Backed by an array: Like ArrayList, Vector stores elements in an internal Object[] elementData.
2.Fully synchronized: Nearly all public methods (add, get, remove, etc.) are wrapped in synchronized, 
ensuring thread-safety 
3.Resizable with growth factor: By default, Vector doubles its capacity when full (new cap = oldCap * 2). 
You can specify a custom capacityIncrement via the two-argument constructor .
4.Supports Enumeration + Iterator: Legacy elements() returns non–fail-fast Enumeration; 
(Enumeration is a java legacy used to interate over vector this is a fail safe iterator)
modern iterator() is fail-fast via modCount tracking

TimeComplexity:
1.add(E e) (append): O(1) amortized—bottleneck is array resize, but every call is synchronized.
2.get(index), set(index, E): O(1), with synchronization.
3.add(index, E), remove(index): O(n)—requires shifting elements, still synchronized.
4.remove(Object o), contains(o), indexOf(o): O(n) via linear search.
5.size(), isEmpty(): O(1), synchronized.

Advantage:
1.Built-in thread safety: Synchronous locking on each method makes it safe for concurrent access—even if coarse-grained.
2.Customizable growth strategy: Ability to define capacityIncrement for memory-control use cases 
3.Legacy backwards compatibility: Available in older Java versions; supports Enumeration.
Drawbacks:
1.Performance penalty: Synchronization on every method adds overhead—even in single-threaded scenarios 
2.Memory inefficiency: Doubling capacity may result in excess unused space compared 
to scaling by 1.5× (used by ArrayList) .
3.Leans on legacy patterns: Enumeration is outdated; modern code typically prefers ArrayList 
or CopyOnWriteArrayList for thread-safe needs 
4.Misleading thread safety: While methods are atomic, combined operations aren't necessarily 
thread-safe, and bulk operations still require external synchronization.

----------------------------------------------------------------------------------------------------------
HashMap Internal Implementation:
Hashmap stores key value pairs and not in insertion order.
1.A HashMap maintains an array of buckets; each bucket can hold multiple entries.
2. Here each bucket is a Node<K,V> which contains
hash (an optimized hashCode)
key, value
next pointer for chaining within the same bucket 
3.When creating a new HashMap with no arguments then the default size of the array of buckets is 16
i.e Node<K,V>[] table -> with the size of 16 and load factor is 0.75
Initial capacity = 16 because it's a power of two simplifies hashing and keeps performance efficient.
4.LoadFactor = no of elements/ size of the table
since the default load factor is 0.75 then the no of elements accepted is 12
if the 13th element is inserted then the array size doubles to 32 and all entries are re hashed into new buckets(nodes)
5.While adding a new element with key and value the hashmap uses the hash method to calculate the hashCode
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);   // >>> means Unsigned (logical) right shift
}
Now the bucket(node) index is calulated
int index = (n - 1) & hash; // n = current bucket array length
Using bitwise AND is faster than modulo and requires the bucket array size to be a power of two
6.After calculating the index a new node is created and is inserted at that index.
7.Handling Collisions If two keys map to the same bucket(node) index (“collision”):
	a)Before-Java 8: Entries were linked in a simple chain (linked list).
	  If any different keys result in the same index then the new node is appended or prepended to the node present at that index
	This makes the get and put costly.
	get, put, remove -> Time complexity is o(n)
	b)After Java8:  If too many colliding entries accumulate in one bucket (usually ≥8) 
	and the bucket array is large enough (≥64 slots), that chain converts to a balanced RED - BLACK TREE, 
	improving lookup times.
	get, put, remove -> Time complexity is o(log n)
8.A Red–Black Tree is a kind of self-balancing binary search tree equipped with a “color” (red or black) 
on each node. These colors, along with key rules, keep the tree approximately balanced and 
guarantee logarithmic height 
Key Properties:
Every node is red or black.
The root is always black.
All leaves (null pointers) are black.
No red node has a red child.
Every path from a node to its leaves contains the same number of black nodes (black-depth)
	
---------------------------------------------------------------------------------------------------------
LinkedHashMap Internal Implementation
LinkedHashMap<K,V> extends HashMap<K,V> and combines a hash table with a doubly linked list
allowing it to maintain predictable iteration order—either by insertion or access 

Entry Class: Internally, LinkedHashMap.Entry extends HashMap.Node (or Entry), 
adding two additional fields: before and after, used to link entries in insertion or access order. 
Doubly-Linked List Anchoring: A circular sentinel node (header) is used to refer to the first and last entries. 
Insertion calls link new entries into the list, updating neighbors accordingly.

Summary Flow
put() → calls HashMap.putVal()
HashMap.putVal() → invokes newNode(...) → creates entry and appends to linked list (linkNodeAtEnd(...))
On access with access-order = true → invokes afterNodeAccess(...) to reorder entry
Upon insertion, afterNodeInsertion(...) may trigger eviction of the eldest entry

--------------------------------------------------------------------------------------------------------------
TreeMap internal implementation
Internal Backbone: Red‑Black Tree (Self‑Balancing BST)

TreeMap doesn't use hashing or buckets. 
Instead, it stores entries in a Red-Black Tree, a self-balancing binary search tree (BST), 
which ensures O(log n) operations for get, put, remove, and containsKey.

Each node is an instance of the internal static class Entry<K,V>, which carries:
K key, V value
Entry<K,V> left, right, parent
boolean color, defining RED or BLACK status

Tree Characteristics & Red-Black Properties
A Red-Black Tree maintains balance via these rules:
Every node is either RED or BLACK.
The root is always BLACK.
A RED node cannot have RED children.
Every path from the root to a leaf (NULL) has the same number of BLACK nodes.
All leaves (represented as NIL) are BLACK.

| Feature                    | Description                                                                    |                                             |
| -------------------------- | ------------------------------------------------------------------------------ | ------------------------------------------- |
| **Base Structure**         | Based on a Red-Black Tree (self-balancing BST)                                 |                                             |
| **Node Representation**    | `Entry<K,V>` with pointers `left`, `right`, `parent`, plus `color` (RED/BLACK) |                                             |
| **Balancing After Insert** | `fixAfterInsertion()` handles rotations and color balancing                    |                                             |
| **Balancing After Delete** | `fixAfterDeletion()` restores tree invariants                                  |                                             |
| **Performance Guarantees** | `O(log n)` for insertion, deletion, lookup—even in worst-case scenarios        |                                             |
| **Sorting Behavior**       | Automatically sorted by natural order or provided `Comparator`                 |                                             |
| **Fail-fast Behavior**     | Iterators throw `ConcurrentModificationException` on concurrent modifications  | ([GeeksforGeeks][1], [dineshonjava.com][2]) |

Example:
1.TreeMap with default ascending order
TreeMap<Integer, String> map = new TreeMap<>();
// Uses natural (ascending) order of keys
map.put(1, "One");
map.put(3, "Three");
map.put(2, "Two");
System.out.println(map);
// Output: {1=One, 2=Two, 3=Three}

2.TreeMap with descending order
TreeMap<Integer, String> reverseMap =
    new TreeMap<>(Collections.reverseOrder());
reverseMap.put(1, "One");
reverseMap.put(3, "Three");
reverseMap.put(2, "Two");
System.out.println(reverseMap);
// Output: {3=Three, 2=Two, 1=One}

--------------------------------------------------------------------------------------------------------------
HashSet internal implementation
Backed by HashMap
Every HashSet internally uses a HashMap to manage its elements. When you add an element to the HashSet, 
it becomes a key in the backing HashMap, with a constant dummy value as its associated value. 
This avoids duplicating complex hash table logic, allowing HashSet to leverage HashMap's efficient implementation.

Internal Structure
private transient HashMap<E, Object> map;
private static final Object PRESENT = new Object();
The map holds elements as keys, and PRESENT is a dummy value for every key
add(Object e)
public boolean add(E e) {
  return map.put(e, PRESENT) == null;
}
Returns true if the element was not already present
remove(Object o)
public boolean remove(Object o) {
  return map.remove(o) == PRESENT;
}
Removes the element and returns true if it existed.
contains(Object o)
Just checks if the key exists in the map: map.containsKey(o). 
iterator()
Iterates over map.keySet(), returning all elements stored in the set

| Concept            | Description                                                       |
| ------------------ | ----------------------------------------------------------------- |
| Backing            | Uses `HashMap` internally with dummy `PRESENT` value for each key |
| `add()`            | Calls `map.put(key, PRESENT)`, returns true if newly added        |
| `remove()`         | Uses `map.remove(object)`, checks if value was `PRESENT`          |
| `contains()`       | Delegates to `map.containsKey(object)`                            |
| Iteration          | Iterates elements through `map.keySet()`                          |
| Collision Handling | Linked list (≤ Java 7), Tree structure threshold (≥ Java 8)       |
| Resizing Policy    | Resizes based on load factor; rehashes entries accordingly        |

--------------------------------------------------------------------------------------------------------------------------
Linked HashSet Internal Implementation
Internal Structure of LinkedHashSet
1. Backed by LinkedHashMap
Internally, LinkedHashSet doesn't store elements directly. Instead, it leverages a LinkedHashMap to hold its entries. 
Each element is stored as a key in the LinkedHashMap, with a constant dummy value (PRESENT) for every key.
This design allows LinkedHashSet to benefit from the efficient hash-based operations of HashMap, 
while also maintaining predictable ordering through the linked list feature of LinkedHashMap.

In Summary
LinkedHashSet internally uses a LinkedHashMap to store elements.
It inherits behavior from HashSet, but adds a doubly-linked list to maintain predictable insertion order.
Offers O(1) operations with reliable iteration order and moderate overhead.
Constructors initialize the backing LinkedHashMap, linking elements while preserving order.

---------------------------------------------------------------------------------------------------------------------
TreeSet Internal Implementation
Backed by TreeMap
A TreeSet doesn’t store its elements directly. Instead, it wraps a TreeMap, 
storing each element as a key with a constant dummy object as its value. Internally, this is captured by:

private transient NavigableMap<E,Object> m;
TreeSet() { this.m = new TreeMap<>(); }

---------------------------------------------------------------------------------------------------------------------
Queue:
	->Deque
the following are the primary non-concurrent implementations of the Queue interface:
LinkedList
ArrayDeque
PriorityQueue

The ArrayDeque class in Java is a resizable-array implementation of the Deque interface
ArrayDeque (short for "Array Double-Ended Queue") is a class in Java that implements the Deque interface using a resizable array. 
It allows elements to be added or removed from both ends efficiently, making it a versatile choice for various data structure needs

Internal Structure

Internally, ArrayDeque uses a circular array to store elements. This design allows for efficient operations at both ends of the deque. The array is dynamically resized as needed to accommodate more elements.

Key aspects of its internal structure include:
Resizable Array: The internal array grows automatically as elements are added. 
The default initial capacity is 16, and it doubles in size when the array is full.
Head and Tail Pointers: Two pointers, head and tail, track the front and rear of the deque, respectively. 
These pointers are updated during insertion and removal operations.
Circular Indexing: The array is treated as circular, meaning that when the head or tail pointer reaches the end of the array, 
it wraps around to the beginning. This allows for efficient use of space.

Key Features
Resizable Array: Internally, ArrayDeque uses a circular array that automatically grows as needed, typically doubling in size when full. 
No Capacity Restrictions: It has no fixed capacity limit; it will grow automatically as more elements are added. 
No Null Elements: Unlike some other collections, ArrayDeque does not allow null elements.
Not Thread-Safe: ArrayDeque is not synchronized, so it's not thread-safe. External synchronization is required if multiple threads access it concurrently.
Efficient Operations: It provides constant-time performance (O(1)) for adding, removing, and accessing elements at both ends

Common Use Cases
Implementing Stacks: By using push() and pop(), ArrayDeque can function as a stack, providing LIFO behavior.
Implementing Queues: Using offer() and poll(), it can serve as a queue, offering FIFO behavior.
Implementing Stacks: By using addFirst() and removeFirst(), ArrayDeque can function as a stack, providing Last-In-First-Out (LIFO) behavior.
Implementing Queues: Using addLast() and removeFirst(), it can serve as a queue, offering First-In-First-Out (FIFO) behavior.
Undo/Redo Functionality: Ideal for managing undo and redo operations in applications.
Tree Traversal: Useful for implementing breadth-first search (BFS) and depth-first search (DFS) algorithms.
Buffering Mechanisms: Suitable for buffering data in parsers or data streams

Example:
import java.util.ArrayDeque;
import java.util.Deque;

public class ArrayDequeExample {
    public static void main(String[] args) {
        // Using ArrayDeque as a Stack
        Deque<String> stack = new ArrayDeque<>();
        stack.push("First");
        stack.push("Second");
        System.out.println("Stack pop: " + stack.pop()); // Outputs: Second

        // Using ArrayDeque as a Queue
        Deque<String> queue = new ArrayDeque<>();
        queue.offer("Task1");
        queue.offer("Task2");
        System.out.println("Queue poll: " + queue.poll()); // Outputs: Task1
    }
}


Advantages Over Alternatives
Performance: ArrayDeque is faster than LinkedList for adding and removing elements at both ends. 
Memory Efficiency: It uses less memory compared to LinkedList because it doesn't require storing pointers for each element.
Versatility: It can be used as both a stack and a queue, providing flexibility in various scenarios.

--------------------------------------------------------------------------------------------------------------------
PriorityQueue
In Java, the PriorityQueue class is a part of the Java Collections Framework and provides an implementation of a priority queue. 
It orders elements based on their natural ordering or by a comparator provided at queue construction time.

Internal Implementation
Internally, PriorityQueue uses a binary heap data structure, specifically a min-heap by default. 
In a min-heap, the smallest element is at the root, ensuring that retrieval operations like peek() or poll() 
can access the least element in constant time. This structure allows for efficient insertion and removal operations, both of 
which have a time complexity of O(log n).

Constructors
PriorityQueue offers several constructors to accommodate different use cases:
PriorityQueue(): Creates a priority queue with the default initial capacity (11) that orders its elements according to their 
natural ordering.
PriorityQueue(int initialCapacity): Creates a priority queue with the specified initial capacity that orders its elements 
according to their natural ordering.
PriorityQueue(int initialCapacity, Comparator<? super E> comparator): Creates a priority queue with the specified initial 
capacity that orders its elements according to the specified comparator.
PriorityQueue(Collection<? extends E> c): Creates a priority queue containing the elements in the specified collection.
PriorityQueue(PriorityQueue<? extends E> c): Creates a priority queue containing the elements in the specified priority queue.
PriorityQueue(SortedSet<? extends E> c): Creates a priority queue containing the elements in the specified sorted set

| Method               | Description                                                        |                                                                        |
| -------------------- | ------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| `add(E e)`           | Inserts the specified element into the priority queue.             |                                                                        |
| `offer(E e)`         | Inserts the specified element into the priority queue.             |                                                                        |
| `peek()`             | Retrieves, but does not remove, the head of the queue.             |                                                                        |
| `poll()`             | Retrieves and removes the head of the queue.                       |                                                                        |
| `remove(Object o)`   | Removes a single instance of the specified element from the queue. |                                                                        |
| `contains(Object o)` | Returns `true` if the queue contains the specified element.        |                                                                        |
| `size()`             | Returns the number of elements in the queue.                       |                                                                        |
| `clear()`            | Removes all elements from the queue.                               | ([Wikipedia][1], [Oracle Documentation][2], [Oracle Documentation][3]) |

Important Notes
Null Elements: PriorityQueue does not permit null elements. Attempting to insert a null element will result in a NullPointerException.
Thread Safety: This implementation is not synchronized. Multiple threads should not access a PriorityQueue instance concurrently if 
any of the threads modifies the queue. Instead, use the thread-safe PriorityBlockingQueue class. 
Ordering: If elements are not comparable, a ClassCastException will be thrown when attempting to insert them into the queue.

Use Cases
PriorityQueue is particularly useful in scenarios where you need to process elements based on priority, such as:
Task Scheduling: Managing tasks where each task has a different priority level.
Dijkstra's Shortest Path Algorithm: Efficiently selecting the next node to process.
Huffman Encoding: Building an optimal prefix code for data compression.
Event Simulation: Handling events in a simulation where events occur at different times.

---------------------------------------------------------------------------------------------------------------------
Concurrent Collections:
Java provides thread-safe variants in java.util.concurrent:
1.ConcurrentHashMap (ConcurrentMap):
Java 7 and Earlier: Segmented Locking
Internally, the map is divided into segments (default count 16) — each segment is essentially a small 
Hash table wrapped in a ReentrantLock 
Writes require acquiring the lock for just the segment covering the key, enabling concurrent updates across different segments.
Reads are lock-free and allowed to proceed concurrently 
The concurrency level parameter in constructors is mainly a sizing hint affecting the number of segments

Java 8 and Later: Bucket-Level Locking + CAS + Treeification
Core Data Structure
The segmented model is replaced with a single table: volatile Node<K,V>[] table, where each Node is like a linked list entry: 
(hash, key, volatile V val, next, ...) 
Buckets hold either linked lists or, once too many collisions occur, are converted into 
balanced trees (TreeBins) to improve lookup performance from O(n) to O(log n) 

Writes & CAS
On insert (put), the bucket index is computed with a hash function spread to distribute well.
If the bucket is empty: a CAS insert initializes it — no locking needed.
If not empty: synchronization is applied only on that bucket. The first node (or TreeBin) acts like a lock monitor 
Collisions beyond a threshold trigger treeification to keep performance optimal

| Aspect                     | Java 7 and Earlier                        | Java 8 and Later                                                             |
| -------------------------- | ----------------------------------------- | ---------------------------------------------------------------------------- |
| **Locking Strategy**       | Segment-level locks with `ReentrantLock`s | Per-bucket `synchronized` + CAS for initial nodes                            |
| **Concurrency Level**      | Limited (by number of segments)           | Scales with bucket-level granularity                                         |
| **Bucket Structure**       | Linked-list only                          | Linked-list; converts to Tree (`TreeBin`) if large                           |
| **Resizing Behavior**      | Blocking, single-threaded                 | Concurrent, cooperative across threads                                       |
| **Memory & Compatibility** | Uses legacy segments, heavier overhead    | Leaner design, segments remain only for serialization  ([Stack Overflow][1]) |

--------------------------------------------------------------------------------------------------------------------------
2.ConcurrentSkipListMap
A thread-safe implementation of ConcurrentNavigableMap, introduced in Java 1.6, 
offering sorted key ordering and concurrent access ([turn0search0]turn0search1).
Ideal for scenarios requiring ordered maps under concurrent read/write workloads.
Internal Structure: The Skip List Primer
The map uses a skip list data structure: multiple levels of sorted linked lists where higher levels skip over entries, enabling O(log n) expected time for get, put, remove, and navigation operations ([turn0search8]turn0search6).
Each node maintains forward pointers at various levels (probabilistically assigned) alongside key and value fields ([turn0search8]).

3.ConcurrentSkipListSet
A thread-safe, sorted, NavigableSet implementation backed by a ConcurrentSkipListMap.
It maintains elements in sorted order (natural or via comparator) and supports concurrent access by multiple threads safely.
Provides expected O(log n) time complexity for contains, add, and remove operations.
Iterators and spliterators are weakly consistent: they reflect some snapshot in time, may continue as collection changes, 
and never throw ConcurrentModificationException.

4.BlockingQueue implementations: ArrayBlockingQueue, LinkedBlockingQueue, etc.
ArrayBlockingQueue
A bounded, array-based blocking queue implementing FIFO ordering and backed by a fixed-size array specified at construction. Null elements are not allowed. 
Core synchronization:
Uses a single ReentrantLock to guard both put (insert) and take (remove) operations.
Optional fairness mode (passed in constructor) governs whether waiting threads are served FIFO. 
Fairness reduces starvation but may degrade throughput. 
Blocking behavior:
put() blocks when the array is full.
take() blocks when the queue is empty.
Threads await on Conditions until queue state changes. 
Order and performance:
Strict FIFO.
Capacity fixed on creation.
Simplicity yields predictable performance under moderate concurrency.

LinkedBlockingQueue
A (optionally) bounded, linked‑node FIFO queue, backed by a singly-linked list of Node<E> entries (each with item and next). 
Thread safety:
Uses two ReentrantLocks: one for producers (putLock) and one for consumers (takeLock), reducing contention between put and take operations. 
Two Conditions: notFull (on putLock) and notEmpty (on takeLock) control blocking behavior.
put(e):
Locks putLock.
Waits if queue size equals capacity.
Enqueues new node at tail, increments count (an AtomicInteger).
Signals notEmpty if necessary.

5.CopyOnWriteArrayList 
A thread-safe variant of ArrayList in java.util.concurrent.
Every mutation (e.g. add, set, remove) creates a fresh copy of the underlying array.
Optimized for read-heavy workloads where traversals vastly outnumber writes.
Iterators are snapshot-based, reflecting the state at creation time and immune to concurrent modifications.
Underlying Array & Thread Safety
Internally stores elements in a volatile Object[] array.
Readers (get, iteration) access this volatile array without locks—lock-free reads.
Writers acquire an internal ReentrantLock, clone the array, apply the mutation, then atomically replace the volatile reference
Mutation Flow (e.g., add(e)):
Lock is acquired.
A new array of length+1 is copied from the current one.
New element is appended.
volatile array reference is updated.
Lock is released.

6.CopyOnWriteArraySet
A thread-safe Set implementation in java.util.concurrent, backed by a CopyOnWriteArrayList.
Best suited when the set size remains small, reads vastly outnumber writes, and safe iteration is crucia
Mutation operations (e.g., add, remove):
Acquire an internal lock.
Copy the entire backing array to a new one.
Apply the change.
Atomically update the reference.
Duplicate prevention: add() checks presence before copying. If the element already exists, it returns false without copying

Difference between Collections.synchronizedList and Concurrency Collections
Collections.synchronizedList(...)
Wraps a standard list (e.g. ArrayList) in a mutex-synchronized proxy.
All public methods (add, get, remove, etc.) are wrapped in synchronized(this) blocks, serializing access. Each operation acquires a global lock. 
Iteration safety is NOT automatic—you must manually synchronize during iteration to avoid undefined behavior or exceptions:

-------------------------------------------------------------------------------------------------------=
volatile vs Atomic
volatile Keyword:
Guarantees
Visibility: Updates to a volatile variable are immediately visible to other threads. All threads read the latest value.
---------------------------------------------------------------------------------------------------------
Collections Utility Class
This class is packed with static methods for operating on or creating Collection objects (Lists, Sets, Maps):
1.sort(List<T>) – Sorts in-place using natural ordering or a Comparator:
2.binarySearch(List<T>, key) – After sorting, finds the index of key in O(log n) time:
int pos = Collections.binarySearch(names, "Alice");
3.reverse(List<?>), shuffle(List<?>), fill(List<?>, T):
Collections.reverse(list);
Collections.shuffle(list);
Collections.fill(list, "x");
4.min, max, frequency – Compute minimum, maximum, and count occurrences:
T smallest = Collections.min(list);
int count = Collections.frequency(list, element);
5.Thread-safe wrappers: synchronizedList, synchronizedMap, etc.
List<T> syncList = Collections.synchronizedList(myList);
6.Immutable/singleton collections: unmodifiableList, singletonList, emptyList:
List<String> readonly = Collections.unmodifiableList(myList);
List<String> one = Collections.singletonList("only");
---------------------------------------------------------------------------------------------------

Arrays Utility Class
Offers static operations for working with arrays—sorting, searching, copying, filling, comparing, and converting.
1.sort() and parallelSort()
sort(T[]), optionally with a Comparator.
parallelSort (Java 8+) uses multiple threads for large primitive arrays
2.binarySearch() – Binary search on sorted arrays in O(log n) time
3.fill() – Assigns a value to all or a range in the array
int[] arr = new int[5];
Arrays.fill(arr, 2);
System.out.println(Arrays.toString(arr)); // [2, 2, 2, 2, 2]
4.Copying & subrange: copyOf, copyOfRange to duplicate or extract subarrays
int[] src = {1, 2, 3};
int[] copy1 = Arrays.copyOf(src, 5);
System.out.println(Arrays.toString(copy1)); // [1, 2, 3, 0, 0]

String[] names = {"Alice", "Bob"};
String[] copy2 = Arrays.copyOf(names, 4);
System.out.println(Arrays.toString(copy2)); // [Alice, Bob, null, null]

int[] src = {10, 20, 30, 40, 50};
int[] sub1 = Arrays.copyOfRange(src, 1, 4);
System.out.println(Arrays.toString(sub1)); // [20, 30, 40]

int[] sub2 = Arrays.copyOfRange(src, 3, 8);
System.out.println(Arrays.toString(sub2)); // [40, 50, 0, 0, 0]

5.asList(T...) – Wraps array as fixed-size List, backed by the original
String[] arr = {"a", "b", "c"};
List<String> list = Arrays.asList(arr);
Returns a fixed-size list backed by the original array
Mutating the list updates the array (and vice versa)
Doesn't support add or remove (throws UnsupportedOperationException)

6.Comparison & hashing:
equals, deepEquals (multidimensional), hashCode, deepHashCode, compare, mismatch
7.Representation & streaming:
toString(), deepToString(), stream(), spliterator()
-------------------------------------------------------------------------------------------------------